{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tensor의 조작\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor([1, 2])\n",
      "tensor([4])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([2, 4, 6, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 인덱싱, 슬라이싱\n",
    "\n",
    "a=torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "print(a[0,1])\n",
    "print(a[0,:])\n",
    "\n",
    "a=torch.tensor([1,2,3,4,5])\n",
    "print(a[-2:-1])\n",
    "\n",
    "\n",
    "# 조건부\n",
    "a=torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(a[a>5])\n",
    "print(a[a%2==0])\n",
    "\n",
    "\n",
    "# 인덱싱의 인덱싱\n",
    "print(a[[0,1],[1,2]])               #a[0,1], a[1,2]를 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5392, 0.6905, 0.0715, 0.5802, 0.3574],\n",
      "        [0.4564, 0.6391, 0.3270, 0.5542, 0.5138],\n",
      "        [0.4390, 0.1952, 0.0746, 0.0900, 0.3367],\n",
      "        [0.9370, 0.3408, 0.6305, 0.6427, 0.8568]])\n",
      "tensor([[0.5392, 0.6905, 0.0715, 0.5802],\n",
      "        [0.3574, 0.4564, 0.6391, 0.3270],\n",
      "        [0.5542, 0.5138, 0.4390, 0.1952],\n",
      "        [0.0746, 0.0900, 0.3367, 0.9370],\n",
      "        [0.3408, 0.6305, 0.6427, 0.8568]])\n",
      "tensor([[0.5392, 0.6905],\n",
      "        [0.0715, 0.5802],\n",
      "        [0.3574, 0.4564],\n",
      "        [0.6391, 0.3270],\n",
      "        [0.5542, 0.5138],\n",
      "        [0.4390, 0.1952],\n",
      "        [0.0746, 0.0900],\n",
      "        [0.3367, 0.9370],\n",
      "        [0.3408, 0.6305],\n",
      "        [0.6427, 0.8568]])\n"
     ]
    }
   ],
   "source": [
    "## 텐서의 크기, 모양 변경\n",
    "\n",
    "t=torch.rand(4,5)\n",
    "print(t)\n",
    "\n",
    "x=t.view(5,4)\n",
    "print(x)\n",
    "\n",
    "y=t.view(10,2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "tensor([0.1444])\n",
      "0.1444305181503296\n"
     ]
    }
   ],
   "source": [
    "## 텐서의 숫자가 얻기 (스칼라 값)\n",
    "\n",
    "x=torch.tensor(10)\n",
    "print(x.item())\n",
    "\n",
    "y=torch.rand(1)\n",
    "print(y)\n",
    "print(y.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 1])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3, 3])\n",
      "torch.Size([1, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 차원 축소와 증가\n",
    "\n",
    "'''\n",
    "torch.squeeze(): 크기가 1인 차원을 축소함(없앤다)\n",
    "torch.unsqueeze(): 지정한 위치에 새로운 차원을 생성\n",
    "'''\n",
    "\n",
    "# 차원 축소\n",
    "t=torch.rand(1,3,3,1)\n",
    "print(t.shape)\n",
    "\n",
    "ts=torch.squeeze(t)\n",
    "print(ts.shape)\n",
    "\n",
    "\n",
    "# 차원 생성\n",
    "t=torch.rand(3,3,3)\n",
    "print(t.shape)\n",
    "\n",
    "ts=torch.unsqueeze(t,0)     # 텐서, 위치\n",
    "print(ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n",
      "torch.Size([2, 4])\n",
      "tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10]])\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "## 텐서간 결합\n",
    "'''\n",
    "torch.stack(): 동일한 형식의 텐서를 새롭게 그룹화한다. (새로운 차원이 생성)\n",
    "torch.cat(): 텐서를 하나로 결합(차원을 유지)\n",
    "'''\n",
    "\n",
    "# stack\n",
    "a=torch.tensor([[1,2],[3,4]])     # 2*2\n",
    "b=torch.tensor([[5,6],[7,8]])     # 2*2\n",
    "c=torch.stack([a,b])\n",
    "\n",
    "print(c)\n",
    "print(c.shape)    # 2*2*2\n",
    "\n",
    "# cat\n",
    "a=torch.tensor([[1,2],[3,4]])     # 2*2\n",
    "b=torch.tensor([[5,6],[7,8]])     # 2*2\n",
    "b_2=torch.tensor([[5,6],[7,8],[9,10]])     # 3*2\n",
    "c=torch.cat([a,b], dim=1)    # 0: 열을 고정하여 합, 1: 행을 고정하여 합\n",
    "c_2=torch.cat([a,b_2], dim=0)\n",
    "\n",
    "print(c)\n",
    "print(c.shape)    # 2*4\n",
    "\n",
    "print(c_2)\n",
    "print(c_2.shape)    # 5*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4463, 0.4957, 0.0599],\n",
      "        [0.4870, 0.7192, 0.5215],\n",
      "        [0.9501, 0.0390, 0.1254],\n",
      "        [0.6438, 0.5919, 0.1780],\n",
      "        [0.4634, 0.4419, 0.8537]])\n",
      "tensor([[0.4463, 0.4957, 0.0599],\n",
      "        [0.4870, 0.7192, 0.5215]])\n",
      "tensor([[0.9501, 0.0390, 0.1254],\n",
      "        [0.6438, 0.5919, 0.1780]])\n",
      "tensor([[0.4634, 0.4419, 0.8537]])\n"
     ]
    }
   ],
   "source": [
    "## 텐서 나누기\n",
    "'''\n",
    "torch.chunk(): 텐서를 몇개로 나눌지를 지정하여 나눔, 나누어 떨어지지 않으면 마지막 조각은 크기가 다름\n",
    "torch.split(): 텐서의 지정된 크기를 기준으로 나누기\n",
    "'''\n",
    "\n",
    "# chunk\n",
    "t=torch.rand(5,3)\n",
    "print(t)\n",
    "\n",
    "a,b,c=torch.chunk(t,3, dim=0)     # 탠서, 나눌 값, 0: 행기준으로 쪼개기 1: 열기준으로 쪼개기\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7615, 0.4731, 0.0051, 0.4392, 0.7648, 0.4678],\n",
      "        [0.1629, 0.2491, 0.8901, 0.7847, 0.4168, 0.0211],\n",
      "        [0.8969, 0.0027, 0.4842, 0.3437, 0.4616, 0.7461]])\n",
      "tensor([[0.7615, 0.4731, 0.0051, 0.4392],\n",
      "        [0.1629, 0.2491, 0.8901, 0.7847],\n",
      "        [0.8969, 0.0027, 0.4842, 0.3437]])\n",
      "tensor([[0.7648, 0.4678],\n",
      "        [0.4168, 0.0211],\n",
      "        [0.4616, 0.7461]])\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5]])\n",
      "tensor([[1, 2],\n",
      "        [1, 2]])\n",
      "tensor([[3, 4],\n",
      "        [3, 4]])\n",
      "tensor([[5],\n",
      "        [5]])\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "t=torch.rand(3,6)\n",
    "print(t)\n",
    "\n",
    "a,b=torch.split(t, 4, dim=1)      # 0: 행 기준으로 나누기,  1: 열 기준으로 나누기\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "t_1=torch.tensor([[1,2,3,4,5],[1,2,3,4,5]])\n",
    "print(t_1)\n",
    "c,d,e=torch.split(t_1, [2,2,1], dim=1)      # 0: 행 기준으로 나누기,  1: 열 기준으로 나누기\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
